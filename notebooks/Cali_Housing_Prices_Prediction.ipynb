{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Install and Import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Load and Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data into train and test sets FIRST to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features using training data statistics\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # Use scaler from training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Define and Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define an improved neural network for regression\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    # keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    # keras.layers.Dropout(0.3),\n",
    "    # keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Linear activation for regression\n",
    "])\n",
    "\n",
    "# Compile with appropriate metrics (MAE/MSE)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train for more epochs with validation\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate properly\n",
    "print(\"\\nFinal evaluation:\")\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test MSE: {test_loss:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "# Extract model parameters\n",
    "config = {\"layers\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Plot the Training and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Record total inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Take one example from the test set and compare prediction vs true label\n",
    "sample_index = 1\n",
    "sample_input = X_test[sample_index]\n",
    "true_label = y_test[sample_index]\n",
    "\n",
    "# Reshape the input for prediction (model expects batch dimension)\n",
    "sample_input = sample_input.reshape(1, -1)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Predict\n",
    "predicted_label = model.predict(sample_input, verbose=0)[0][0]\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Print comparison\n",
    "print(f\"\\nTest Sample {sample_index}:\")\n",
    "# print(f\"  - Input Features: {sample_input.flatten()}\")\n",
    "print(f\"  - True Label: {true_label:.4f}\")\n",
    "print(f\"  - Predicted Label: {predicted_label:.4f}\")\n",
    "print(f\"  - Inference Time: {inference_time:.4f}\")\n",
    "# print(f\"  - Absolute Error: {abs(true_label - predicted_label):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Save model weights to config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input layer\n",
    "config[\"layers\"].append({\n",
    "    \"type\": \"input\",\n",
    "    \"nodes\": X.shape[1],\n",
    "    \"values\": [0] * X.shape[1]  # Placeholder values\n",
    "})\n",
    "\n",
    "# Hidden and output layers\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, keras.layers.Dense):\n",
    "        weights, biases = layer.get_weights()\n",
    "        num_nodes = weights.shape[1]\n",
    "        activation = layer.activation.__name__\n",
    "        \n",
    "        neurons = []\n",
    "        for i in range(num_nodes):\n",
    "            neuron_weights = weights[:, i].tolist()\n",
    "            neuron_bias = biases[i].item()\n",
    "            neurons.append({\"weights\": neuron_weights, \"bias\": neuron_bias, \"activation\": activation})\n",
    "        \n",
    "        layer_type = \"output\" if num_nodes == 1 else \"hidden\"\n",
    "        config[\"layers\"].append({\n",
    "            \"type\": layer_type,\n",
    "            \"nodes\": num_nodes,\n",
    "            \"neurons\": neurons\n",
    "        })\n",
    "         \n",
    "# Save to config.json\n",
    "with open(\"config_cali.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"config.json file generated successfully!\")\n",
    "\n",
    "# Save example inputs to example_inputs.json\n",
    "example_inputs = {\"examples\": X_test[:5].tolist()}\n",
    "with open(\"example_inputs_cali.json\", \"w\") as f:\n",
    "    json.dump(example_inputs, f, indent=2)\n",
    "\n",
    "print(\"example_inputs.json file generated successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
